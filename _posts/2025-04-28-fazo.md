---
title: Modul 4. Vektor Fazolari va Ortogonalizatsiya
author: Qilichbek Haydarov
date: 2025-02-28
category: Jekyll
layout: post
---

<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/gZHZuSDF5fg?si=SaaW79TwQwzMW5Gp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</center>


<img src="../assets/rockets.jpg" >

4.1 Vektor fazolari, subfazolar va chiziqli qobiqlar
-------------
### 4.1.1 Vektor fazo va subfazolar

Tasavvur qiling, butun koinot sizning o'yin maydoningiz va vektorlar kosmik raketalarga o'xshaydi. Vektor fazosi barcha raketalar (vektorlar) amal qilishi kerak bo'lgan maxsus qoidalarga ega galaktikaga deb tasavvur qilsak bo'ladi.

Har bir raketa o'zining:
- **yo'nalishi** (masalan, qaysi tomonga uchayotgani)
- **tezligi** (uning dvigatellari qanchalik kuchli ekanligi)

ega bo'ladi.

Vektor fazo esa raketalar o'zaro qanday munosabatda bo'lishi va bir-biriga qanday ta'sir qilishini belgilovchi qoidalardan iborat:
1. **Vektorlar qo'shilishi**: Agar siz ikkita raketani bir-biriga bog'lasangiz, ularning tezligi va yo'nalishlari qanday o'zgaradi?
2. **Vektorlarni skalar songa ko'paytirish**: Agar siz raketani kuchli dvigatel bilan jihozlasangiz, u qanday tezlikka ega bo'ladi?
3. ...


> ##### Vektor fazo
>
> bo'sh bo'lmagan vektor to'plami $V$ bo'lib, u quyidagi shartlarni qanoatlantirsa, $V$ vektor fazosi deyiladi:
> - $V$ to'plamida **nol** vektori mavjud.
> - $V$ to'plamida har qanday $\mathbf{u}, \mathbf{v} \in V$ vektorlar uchun $\mathbf{u} + \mathbf{v} \in V$.
> - $V$ to'plamida har qanday $\mathbf{u} \in V$ vektori va har qanday $c \in \mathbb{R}$ skalar uchun $c\mathbf{u} \in V$.
> - $V$ to'plamida har qanday $\mathbf{u}, \mathbf{v} \in V$ vektorlar uchun $\mathbf{u} + \mathbf{v} = \mathbf{v} + \mathbf{u}$.
> - $V$ to'plamida har qanday $\mathbf{u}, \mathbf{v}, \mathbf{w} \in V$ vektorlar uchun $(\mathbf{u} + \mathbf{v}) + \mathbf{w} = \mathbf{u} + (\mathbf{v} + \mathbf{w})$
> - $V$ to'plamida har qanday $\mathbf{u} \in V$ vektori uchun $\mathbf{u} + (-\mathbf{u}) = \mathbf{0}$.
> - $V$ to'plamida har qanday $\mathbf{u} \in V$ vektori va har qanday $c, d \in \mathbb{R}$ skalarlar uchun $c(d\mathbf{u}) = (cd)\mathbf{u}$.
> - $V$ to'plamida har qanday $\mathbf{u} \in V$ vektori va har qanday $c, d \in \mathbb{R}$ skalarlar uchun $(c + d)\mathbf{u} = c\mathbf{u} + d\mathbf{u}$.
{: .block-tip }

Misollar:
- $\mathbb{R}^2$ - ikki o'lchovli fazo
- $\mathbb{R}^3$ - uch o'lchovli fazo
- $\mathbb{R}^n$ - $n$ o'lchovli fazo

> ##### Vektor subfazosi
> $\mathbf{V}$ fazosining kichik to'plami $\mathbf{U}$ - vektor subfazo deb hisoblanadi, agar ushbu qoidalar qanoatlantirilsa:
> 1. $\mathbf{0} \in \mathbf{U}$
> 2. $\mathbf{u} + \mathbf{v} \in \mathbf{U}$
> 3. $\alpha \mathbf{u} \in \mathbf{U}$
{: .block-tip }

Misol:
- $\mathbb{R}^2$ fazosining subfazosi - $x$ o'qidagi barcha vektorlar to'plami.
- $\mathbb{R}^3$ fazosining subfazosi - $x$ va $y$ o'qlaridagi barcha vektorlar to'plami.


### 4.1.2 Chiziqli qobiq 

<img src="../assets/fleet.webp" >

Tasavvur qiling, endi siz raketalar flotiga (vektorlar) qo'mondonlik qilayotgan kosmik admiralsiz. Sizning flotingiz masofasi - bu ularning kuchlarini birlashtirib (ularni masshtablash va qo'shish) erishishingiz mumkin bo'lgan barcha joylar.

> ##### Chiziqli qobiq (Linear Span)
>
> Agar $\mathbf{v_1}, \mathbf{v_2}, \ldots, \mathbf{v_n}$ vektorlar to'plami berilgan bo'lsa, ularning chiziqli qobi $L(\mathbf{v_1}, \mathbf{v_2}, \ldots, \mathbf{v_n})$ deb ataladi va quyidagi ko'rinishda ifodalanadi:
> $$\boxed{\text{span}(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_n) = \{ \alpha_1 \mathbf{v}_1 + \alpha_2 \mathbf{v}_2 + ... + \alpha_n \mathbf{v}_n | \alpha_i \in \mathbb{R} \}}$$
{: .block-tip }

Misollar: 
- $\text{span}(\begin{bmatrix} 1 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 1 \end{bmatrix})$ - $\mathbb{R}^2$ vektor fazosini tashkil etadi

- $\text{span}(\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 2 \end{bmatrix}, \begin{bmatrix} -1\\ 1/2 \\ 3 \end{bmatrix}, \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix})$ - $\mathbb{R}^3$ vektor fazosini tashkil etadi


### 4.1.3 Bazis (Basis)

Tasavvur qiling, siz galaktika tadqiqotchisisiz va kosmik kemangizning navigatsiya tizimi raketa vektorlarida ishlaydi. **Bazis** bu sizning koinotning istalgan nuqtasiga (vektor fazosi) *ortiqcha raketalarsiz* yetib olishingiz uchun kerak bo'lgan **eng kichik raketalar to'plamidir**.

> ##### Bazis (Basis)
>
> bu vektorlar to'plami $\mathbf{v_1}, \mathbf{v_2}, ..., \mathbf{v_n}$, va $\mathbf{V}$ vektor fazosini tashkil etadi, agar:
- $\text{span}(\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_n) = \mathbf{V}$
- $\mathbf{v}_1, \mathbf{v}_2, ..., \mathbf{v}_n$ o'zaro bog'liq emas
{: .block-tip }

Misollar:
- $\text{span}(\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 2 \end{bmatrix}, \begin{bmatrix} -1\\ 1/2 \\ 3 \end{bmatrix}, \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix})$ - $\mathbb{R}^3$ vektor fazosini tashkil etadi lekin bu bazis emas, chunki ular o'zaro bog'liq
- $\text{span}(\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix})$ - $\mathbb{R}^3$ vektor fazosini tashkil etadi va bu bazis

### 4.1.4 Matritsa rangi (Rank of Matrix)

Tasavvur qiling, siz raketalar flotiga (vektorlarga) ega bo'lgan galaktika qo'mondonisiz, lekin ba'zilari ortiqcha - ular sizning arsenalingizga yangi yo'nalishlarni qo'shmaydi. Matritsaning rangi sizning flotingizda qancha noyob raketa borligini ko'rsatadi.

> ##### Matritsa rangi (Rank of Matrix)
>
>bu ustunlaridan hosil bo'lgan vektor fazosining o'lchami. Ya'ni, *chiziqli bog'liq bo'lmagan* barcha matritsaning ustunlar soni. 
> $$\boxed{\text{rank}(\mathbf{A}) = \text{dim}(\text{span}(\mathbf{A}))}$$
{: .block-tip }

Qanday aniqlaymiz? 


$${\displaystyle {\begin{aligned}{\begin{bmatrix}1&2&1\\-2&-3&1\\3&5&0\end{bmatrix}}&\xrightarrow {2R_{1}+R_{2}\to R_{2}} {\begin{bmatrix}1&2&1\\0&1&3\\3&5&0\end{bmatrix}}\xrightarrow {-3R_{1}+R_{3}\to R_{3}} {\begin{bmatrix}1&2&1\\0&1&3\\0&-1&-3\end{bmatrix}}\\&\xrightarrow {R_{2}+R_{3}\to R_{3}} \,\,{\begin{bmatrix}1&2&1\\0&1&3\\0&0&0\end{bmatrix}}\xrightarrow {-2R_{2}+R_{1}\to R_{1}} {\begin{bmatrix}1&0&-5\\0&1&3\\0&0&0\end{bmatrix}}~.\end{aligned}}}$$

Natijada, $$\text{rank}(\textbf{A}) = 2$$.


### 4.1.5 Ustun fazo va Nol fazo (Column space and Null Space)

1. Ustun fazo: $\text{Col}(\textbf{A}) = \text{span}(\textbf{a}_1, \textbf{a}_2, ..., \textbf{a}_n)$ 
    -  $\textbf{A}$ matritsaning ustunlar qobig'i.
    - Ustun fazo $\textbf{Ax}$ ko'paytirish orqali erishish mumkin bo'lgan barcha vektorlarni ifodalaydi
2. Nol fazo: $\text{Null}(\textbf{A}) = \{ \mathbf{x} \in \mathbb{R}^n \| \textbf{A} \mathbf{x} = \mathbf{0} \}$
    - Nol fazo $\textbf{A}$ matritsaga ko'paytirilganda $\mathbf{0}$ ga aylanadigan barcha vektorlarni ifodalaydi


4.2 Ortogonalizatsiya va Proeksiya (Orthogonalization and Projection)
-------------

### 4.2.1 Ortogonallik 

>##### Ortogonallik
> Agar $\mathbf{u}$ va $\mathbf{v}$ vektorlarining skalar ko'paytmasi $0$ ga teng bo'lsa, u holda $\mathbf{u}$ va $\mathbf{v}$ vektorlar ortogonal (perpendikulyar) deb ataladi.
> $$ \mathbf{u} \cdot \mathbf{v} = 0$$
{: .block-tip }

Misol: 

- $\mathbf{u} = \begin{bmatrix} 1 \\ 2 \end{bmatrix}$ va $\mathbf{v} = \begin{bmatrix} -2 \\ 1 \end{bmatrix}$ ortogonal vektorlar

$$\mathbf{u} \cdot \mathbf{v} = 1 \times -2 + 2 \times 1 = 0$$


### 4.2.2 Proeksiya 

> ##### Proeksiya
>
> bu vektor fazo $\mathbf{V}$ dan o'ziga bo'lgan chiziqli transformatsiya $\mathbf{P}$ hisoblanadi, ya'ni:
> $\mathbf{P}: \mathbb{V} \to \mathbb{V}$, va $\mathbf{P}^2 = \mathbf{P}$.
{: .block-tip }


#### 4.2.2.1 Vektorning o'qdagi Proeksiyasi (Projection onto line) 

![](http://habrastorage.org/files/2fa/2d0/3be/2fa2d03be62e43f3a14f0e4c7bb1398c.png)

Proeksiya $\mathbf{b}$ vektorining $\mathbf{a}$ vektordagi "soyasini" ko'rsatadi .
- $\mathbf{p}$ - $\mathbf{b}$ vektorining $\mathbf{a}$ vektorga proeksiyasi
- $\mathbf{e}$ - proeksiya xatosi (xato minimum bo'lishi uchun $\mathbf{e} \perp \mathbf{a}$)
- $\mathbf{e} = \mathbf{b} - \mathbf{p} = \mathbf{b} - \beta ~ \mathbf{a}$
- Maqsad: $\beta$ ni topish

1. $\mathbf{e} \perp \mathbf{a}$, shunda $\mathbf{a} \cdot \mathbf{e} = 0 \Rightarrow  \mathbf{a}^T (\mathbf{b} - \beta ~ \mathbf{a}) = 0$
$$\boxed{\beta = \frac{\mathbf{a}^T \mathbf{b}}{\mathbf{a}^T \mathbf{a}}}$$
2. Lekin, $\beta = \frac{\| \mathbf{p} \|}{\| \mathbf{a} \|} = \frac{\mathbf{a} \cdot \mathbf{b}}{\| \mathbf{a} \|^2}$ uzunlik
3. Biz $\mathbf{p}$ vektorni topishimiz kerak

Shunchaki $\beta$ ni $\mathbf{a}$ vektorga ko'paytirish kerak:
$${\displaystyle \operatorname {proj} _{\mathbf {a} }\mathbf {b} = \beta~ \mathbf{a} = {\frac {\mathbf {a} \cdot \mathbf {b} }{\left\|\mathbf {a} \right\|^{2}}}{\mathbf {a} }={\frac {\mathbf {a} ^T \mathbf {b} }{\mathbf {a} ^T \mathbf {a} }}{\mathbf {a} }~.}$$

```python
import numpy as np

a = np.array([[0.5], [-2.], [1.5], [-3.], [1.], [0.5]])
b = np.array([[1.], [2.], [3.], [4.], [5.], [6.]])
proj_v = (np.dot(a.T, b) / np.dot(b.T, b)) * b

print(proj_v)
```

#### 4.2.2.2 Proeksiya matritsasi (Projection Matrix)
Berilgan $\displaystyle \operatorname {proj} _{\mathbf {b} }\mathbf {a}={\frac {\mathbf {a} ^T \mathbf {b} }{\mathbf {b} ^T \mathbf {b} }}~{\mathbf {b} } = {\mathbf {b} }~ {\frac {\mathbf {b} ^T \mathbf {a} }{\mathbf {b} ^T \mathbf {b} }}$. Lekin biz buni matritsa yordamida ifodalamoqchimiz: $$\boxed{\textbf{p}=\textbf{Pb}}$$

$${\displaystyle \operatorname {proj} _{\mathbf {b} }\mathbf {a}= \mathbf {b} {\frac {\mathbf {b} ^T \mathbf {a} }{\mathbf {b} ^T \mathbf {b} }}} = {\frac {\mathbf {b} \mathbf {b}^T  }{\mathbf {b} ^T \mathbf {b} }}~{\mathbf {a} } $$
Biz proeksiya matritsasini olamiz:
$$
\textbf{P} = \frac {\mathbf {b} \mathbf {b}^T  }{\mathbf {b} ^T \mathbf {b} }
$$

Xossalari: 

- $ \textbf{P}^T = \textbf{P}$
- $\textbf{P}^2 = \textbf{P}$

```python
import numpy as np

a = np.array([[1], [2], [3]])
b = np.array([[4], [5], [6]])
P = np.dot(b, b.T) / np.dot(b.T, b)
print(P)
print(P @ P)

proj_v = np.dot(P, a)
print(proj_v)
```


#### 4.2.2.3 Vektorning subfazoga proeksiyasi (Projection onto subspace)

Faraz qilaylik, $\mathbf{A}\mathbf{x} = \mathbf{b}$ yechimi yo'q.
- $\mathbf{b} \notin \text{Col}(\mathbf{A})$ - $\mathbf{b}$ vektori $\mathbf{A}$ ustunlar qobig'ida emas
- lekin, $\mathbf{b}$ vektorini proeksiya orqali ustun fazosiga $\text{Col}(\mathbf{A})$ o'tkazish mumkin
- $\text{Col}(\mathbf{A})$ ustun fazosi giper-tekislikni (hyperplane) hosil qiladi.
- $\mathbf{b}$ vektorini giper-tekislikga proeksiya qilish kerak

Misol: Tekislikka proeksiya $\mathbb{R}^3 \rightarrow \mathbb{R}^2$


Faraz qilamiz, $\text{dim}(\text{Col}(\mathbf{A})) = 2$, ya'ni bazis $\mathbf{a_1}, \mathbf{a_2}$ vektorlar to'plami: $\textbf{A} = \Bigg[ \ \mathop{\mathbf a_1}\limits_\|^\| \ \mathop{\mathbf a_2}\limits_\|^\| \ \Bigg]$

<center><img src="http://habrastorage.org/files/245/834/296/245834296b494b6a8f42522ff1feb119.png"
             width=400></center>

- $\mathbf{p} = \hat x_1 ~ \mathbf{a}_1 +  \hat x_2 ~ \mathbf{a}_2 \Rightarrow  \mathbf{p} = \textbf{A}  \mathbf{\hat x}$
- Maqsad: $\mathbf{\hat x}$ ni topish

- $\mathbf{p} = \textbf{A}  \mathbf{\hat x}$
- $\mathbf{e} = \mathbf{b} - \mathbf{p} = \mathbf{b} - \textbf{A}  \mathbf{\hat x}$
- $\mathbf{e} \perp \text{Col}(\mathbf{A})$ - $\mathbf{e} \perp \mathbf{a}_1$ va $\mathbf{e} \perp \mathbf{a}_2$
    - $\mathbf{a}_1^T \mathbf{e} = \mathbf{a}_1^T (\mathbf{b} - \textbf{A}  \mathbf{\hat x}) = 0$
    
    - $\mathbf{a}_2^T \mathbf{e} = \mathbf{a}_2^T (\mathbf{b} - \textbf{A}  \mathbf{\hat x}) = 0$
    
- Matritsa ko'rinishida:
$$\textbf{A}^T (\mathbf{b} - \textbf{A}  \mathbf{\hat x}) = 0$$

$ \mathbf{\hat x} $ topish kerak:
$$\textbf{A}^T (\mathbf{b} - \textbf{A}  \mathbf{\hat x}) = 0$$
$$\textbf{A}^T \textbf{b} - \textbf{A}^T \textbf{A}  \mathbf{\hat x} = 0$$
$$\textbf{A}^T \textbf{A}  \mathbf{\hat x} = \textbf{A}^T \textbf{b}$$
$$\boxed{\mathbf{\hat x} = (\textbf{A}^T \textbf{A})^{-1} \textbf{A}^T \textbf{b}}$$

Lekin, $\mathbf{\hat x}$ bu koeffitsientlar to'plami, proeksiya esa: 
$$\mathbf{p} = \textbf{A}  \mathbf{\hat x} = \textbf{A} (\textbf{A}^T \textbf{A})^{-1} \textbf{A}^T \textbf{b}$$

- $\textbf{P} = \textbf{A} (\textbf{A}^T \textbf{A})^{-1} \textbf{A}^T$ - proeksiya matritsasi


4.3 Ortonormal bazis va Gram-Shmit jarayoni 
-------------

### 4.3.1 Ortonormal bazis (Orthonormal basis)

$\{\textbf{q}_1, \textbf{q}_2, ... \textbf{q}_n \}$ vektorlar to'plami **ortonormal** hisoblanadi, agar:

$$\textbf{q}_i^T \textbf{q}_j=
\begin{cases}
    0, & \text{qachonki} & i\ne j & \text{ortogonal vektor}\\
    1, & \text{when} & i = j & \text{birlik vektor}
\end{cases}$$


Matritsa ko'rinishida:   $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$

- $Q$ - **ortonormal** matritsa deb ataladi

    - $\textit{Q}^T \textit{Q}= \textit{I}$
    - $\textit{Q}^T = \textit{Q}^{-1}$


### 4.3.2 Ortogonal bazisga proeksiya (Projection onto orthogonal basis)

Faraz qilaylik, $Q = \Bigg[ \mathop{\mathbf q_1}\limits_|^| \ \mathop{\mathbf q_2}\limits_|^| \ \cdots \  \mathop{\mathbf q_n}\limits_|^| \Bigg]$ ortonormal bazis bo'lsin. Biz $\mathbf{b}$ vektorini bu bazisga proeksiya qilishimiz kerak. 
- $\text{Col}(Q)$ - $\mathbf{b}$ vektorini proeksiya qilish uchun kerak bo'lgan fazo
- odatda, proeksiya matritsasi $\textbf{P} = \textbf{A} (\textbf{A}^T \textbf{A})^{-1} \textbf{A}^T$ ko'rinishida topiladi
- ortogonal bazis uchun proeksiya matritsasi $\textbf{P} = \textbf{Q} (\textbf{Q}^T \textbf{Q})^{-1} \textbf{Q}^T = \textbf{Q} \textbf{Q}^T$


$$\boxed{\textbf{P} = \textbf{Q} \textbf{Q}^T}$$

```python

import numpy as np

x, y = np.array([[3],[4],[0]]), np.array([[-4],[3],[2]])
print(x.T @ y)
# euclidean norm of x and y
x_norm = np.linalg.norm(x, 2)
y_norm = np.linalg.norm(y, 2)
# normalized x or unit vector
x_unit = x * (1/x_norm)  
y_unit = y * (1/y_norm) 

print(f'Euclidean norm of x:\n{x_norm}\n')
print(f'Euclidean norm of y:\n{y_norm}\n')
print(f'Normalized x:\n{x_unit}\n')
print(f'Normalized y:\n{y_unit}')

print(np.round(np.linalg.norm(x_unit, 2),1),
      np.round(np.linalg.norm(y_unit, 2),1))

print(np.round(x_unit.T @ y_unit,1), 
      np.round(x_unit.T @ x_unit,1), 
      np.round(y_unit.T @ y_unit,1))

Q = np.column_stack((x_unit, y_unit))
print(Q)
print(np.round(Q.T @ Q,1))

```

### 4.3.3 Gram-Shmit jarayoni (Gram-Schmidt process)

Gram-Shmidt jarayoni - bu vektorlar to'plamini ortonormal bazisga aylantirish usuli.
- chiziqli bog'liq bo'lmagan vektorlar to'plamini qabul qiladi: ${\displaystyle S=\{\mathbf {v} _{1},\ldots ,\mathbf {v} _{k}\}}$, $k ≤ n$  
- ortonormal bazis ${\displaystyle S'=\{\mathbf {u} _{1},\ldots ,\mathbf {u} _{k}\}}$ hosil qiladi

<img src="https://gregorygundersen.com/image/gramschmidt/gram-schmidt.png" width=1000>


$$ {\displaystyle {\begin{aligned}\mathbf {u} _{1}&=\mathbf {v} _{1},&\!\mathbf {e} _{1}&={\frac {\mathbf {u} _{1}}{\|\mathbf {u} _{1}\|}}\\\mathbf {u} _{2}&=\mathbf {v} _{2}-\operatorname {proj} _{\mathbf {u} _{1}}(\mathbf {v} _{2}),&\!\mathbf {e} _{2}&={\frac {\mathbf {u} _{2}}{\|\mathbf {u} _{2}\|}}\\\mathbf {u} _{3}&=\mathbf {v} _{3}-\operatorname {proj} _{\mathbf {u} _{1}}(\mathbf {v} _{3})-\operatorname {proj} _{\mathbf {u} _{2}}(\mathbf {v} _{3}),&\!\mathbf {e} _{3}&={\frac {\mathbf {u} _{3}}{\|\mathbf {u} _{3}\|}}\\\mathbf  \ \vdots &&{}\ \ \vdots \\\mathbf {u} _{k}&=\mathbf {v} _{k}-\sum _{j=1}^{k-1}\operatorname {proj} _{\mathbf {u} _{j}}(\mathbf {v} _{k}),&\!\mathbf {e} _{k}&={\frac {\mathbf {u} _{k}}{\|\mathbf {u} _{k}\|}}.\end{aligned}}}$$

```python

import numpy as np

A = np.array([[2, 1, -2],
              [7, -3, 1],
              [-3, 5, -1]])
print(A.T @ A) 

# Gram-Schmidt jarayoni
u1 = A[:, 0]
e1 = u1 / np.linalg.norm(u1)

v2 = A[:, 1]
u2 = v2 - ((u1.T @ v2)/(u1.T @ u1)) * u1
e2 = u2 / np.linalg.norm(u2)

v3 = A[:, 2]
u3 = v3 - (((u1.T @ v3)/(u1.T @ u1)) * u1) - (((u2.T @ v3)/(u2.T @ u2)) * u2) 
e3 = u3 / np.linalg.norm(u3)

Q = np.column_stack((e1, e2, e3))
print(np.round(Q.T @ Q, 2))

```
